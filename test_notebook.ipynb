{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2927b3a-466c-417c-867f-a0f299d08dc4",
   "metadata": {},
   "source": [
    "### Test Mistral API connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1077983-abe5-488e-be42-279f27d99913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Setting up environment ---\n",
      "‚úÖ Found and loaded environment file from: .env\n",
      "‚úÖ API key found, we're ready to roll.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from mistralai import Mistral # CORRECTED: Import Mistral, not MistralClient\n",
    "\n",
    "print(\"--- 1. Setting up environment ---\")\n",
    "\n",
    "# Load your API key from .env file\n",
    "# This assumes your .env file is in the parent directory of the notebook's location\n",
    "env_path = \".env\"\n",
    "if os.path.exists(env_path):\n",
    "    load_dotenv(dotenv_path=env_path)\n",
    "    print(f\"‚úÖ Found and loaded environment file from: {env_path}\")\n",
    "else:\n",
    "    load_dotenv()\n",
    "    print(\"Trying to load from default location...\")\n",
    "\n",
    "# Check if the API key is now available\n",
    "if not os.getenv(\"MISTRAL_API_KEY\"):\n",
    "    print(\"‚ùå No MISTRAL_API_KEY found in environment!\")\n",
    "else:\n",
    "    print(\"‚úÖ API key found, we're ready to roll.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80fa0cc0-5c00-4dd2-885f-9a50478be352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mistral helper function is defined.\n"
     ]
    }
   ],
   "source": [
    "def call_mistral_directly(prompt: str, model: str = \"mistral-small-latest\") -> dict | None:\n",
    "    \"\"\"\n",
    "    Calls the Mistral API directly using the official, correct method.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- 2. Preparing to call Mistral with model: {model} ---\")\n",
    "    \n",
    "    api_key = os.environ.get(\"MISTRAL_API_KEY\")\n",
    "    if not api_key:\n",
    "        print(\"‚ùå Cannot call API, MISTRAL_API_KEY is not set.\")\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        # Initialize the new Mistral client\n",
    "        client = Mistral(api_key=api_key)\n",
    "        \n",
    "        # Prepare the messages payload\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        \n",
    "        # Start timer and make the API call\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # CORRECTED: The official method is client.chat.complete()\n",
    "        response = client.chat.complete(\n",
    "            model=model,\n",
    "            messages=messages\n",
    "        )\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Extract useful info from the response\n",
    "        result = {\n",
    "            \"content\": response.choices[0].message.content,\n",
    "            \"model\": response.model,\n",
    "            \"duration\": end_time - start_time,\n",
    "            \"input_tokens\": response.usage.prompt_tokens,\n",
    "            \"output_tokens\": response.usage.completion_tokens,\n",
    "            \"total_tokens\": response.usage.total_tokens\n",
    "        }\n",
    "        \n",
    "        print(\"‚úÖ API call successful.\")\n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå API call failed: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ Mistral helper function is defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea64a011-6624-448d-9eaf-9d0e6994e9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3. Executing test with prompt: 'What is a 'green job'? Keep it short and practical.' ---\n",
      "\n",
      "--- 2. Preparing to call Mistral with model: mistral-small-latest ---\n",
      "‚úÖ API call successful.\n",
      "\n",
      "==============================\n",
      "üìä TEST CALL RESULTS üìä\n",
      "==============================\n",
      "  Model: mistral-small-latest\n",
      "  Time: 1.10 seconds\n",
      "  Input tokens: 17\n",
      "  Output tokens: 87\n",
      "  Total tokens: 104\n",
      "  Estimated cost: $0.000031\n",
      "\n",
      "------------------------------\n",
      "üí¨ RESPONSE üí¨\n",
      "------------------------------\n",
      "A **green job** is a role that helps reduce environmental harm or supports sustainability. Examples include:\n",
      "\n",
      "- **Renewable energy** (solar/wind technician)\n",
      "- **Energy efficiency** (insulation installer, smart grid engineer)\n",
      "- **Waste management** (recycling coordinator)\n",
      "- **Conservation** (forest ranger, wildlife biologist)\n",
      "\n",
      "These jobs often require skills in tech, engineering, or environmental science.\n",
      "\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# A simple test prompt to ensure everything works\n",
    "test_prompt = \"What is a 'green job'? Keep it short and practical.\"\n",
    "\n",
    "print(f\"\\n--- 3. Executing test with prompt: '{test_prompt}' ---\")\n",
    "result = call_mistral_directly(test_prompt)\n",
    "\n",
    "if result:\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"üìä TEST CALL RESULTS üìä\")\n",
    "    print(\"=\"*30)\n",
    "    print(f\"  Model: {result['model']}\")\n",
    "    print(f\"  Time: {result['duration']:.2f} seconds\")\n",
    "    print(f\"  Input tokens: {result['input_tokens']}\")\n",
    "    print(f\"  Output tokens: {result['output_tokens']}\")\n",
    "    print(f\"  Total tokens: {result['total_tokens']}\")\n",
    "    \n",
    "    # Using pricing for mistral-small-latest as of late 2024\n",
    "    # Input: ~$0.3/M tokens, Output: ~$0.3/M tokens\n",
    "    # We use the higher value for a conservative cost estimate\n",
    "    cost_per_million_tokens = 0.30 \n",
    "    estimated_cost = (result['total_tokens'] / 1_000_000) * cost_per_million_tokens\n",
    "    print(f\"  Estimated cost: ${estimated_cost:.6f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*30)\n",
    "    print(\"üí¨ RESPONSE üí¨\")\n",
    "    print(\"-\"*30)\n",
    "    print(result['content'])\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "else:\n",
    "    print(\"\\n--- Test failed. Please check the error message above. ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46998d1d-0feb-4a1f-9426-4aa8656cddbb",
   "metadata": {},
   "source": [
    "### TEST GDSC API and GDSC credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cd6c700-6f0d-4cf0-a5a6-40678fd42c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Temporary credentials set as environment variables for this session.\n",
      "‚úÖ Successfully imported GDSC utility functions.\n",
      "\n",
      "--- ü©∫ Testing Connection to GDSC API /health endpoint ---\n",
      "‚úÖ API request successful\n",
      "\n",
      "--- üí¨ Testing a live chat with persona_001 ---\n",
      "‚úÖ API request successful\n",
      "üí¨ Conversation count this week: 3\n",
      "\n",
      "üéâ SUCCESS! You have successfully authenticated and chatted with a persona.\n",
      "   Response from persona_001: 'hi i am rafael. i am 21 and want to lern about food saftey and how they make food in factorys. can i get trainig?'\n",
      "   Conversation ID: 871b6377-05a8-436f-bb22-7b61e62309ef#persona_001#2025-10-26T11:53:45\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the project root to the Python path\n",
    "# This allows the notebook to find the 'src' module\n",
    "if '.' not in sys.path:\n",
    "    sys.path.append('.')\n",
    "\n",
    "# --- ‚ö†Ô∏è PASTE YOUR TEMPORARY CREDENTIALS HERE ‚ö†Ô∏è ---\n",
    "# This sets the credentials for this notebook session only.\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"ASIA4MTWODZ7TAJ6V2MD\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"I+g2dUHJpNs74xbXJKXAZSQDG00vWLaJD8NRcoLX\"\n",
    "os.environ[\"AWS_SESSION_TOKEN\"] = \"IQoJb3JpZ2luX2VjEND//////////wEaDGV1LWNlbnRyYWwtMSJIMEYCIQC4CiH0h+pIcdE+RX6sd0hqJDGRUjEBR58NvRoMYRbi1wIhAMOua9loNAXF6kwKVDfSVF5EpcG6fRzegqftNdCvYZx6KqIDCIr//////////wEQABoMODUxNzI1NjU1Njc5Igx+yOsM39Xm0z4M4foq9gKYUz+Qq3H4WW76wq0Q3vrmPusmHG7iWdUyVwwuElfDf9cwsmZ0t2ta6GUkIOxRuNW7ka2Yc37cAxyFRJLUamGhasokHU3k7ked38l0qhgrxoy7T+IXKWcB4pSHmlwxy4tsL7h20cElPq8psgMSGOooVegbJcDNDpBOvu99XhHE9vo+JDgsgtFmfRzd6SUOzufT8wbMMfdwX/WTPlcjTko6zHA1Mxe8kVgYCj3KXzXU5xhrFkC70PGe9/Lt8BXmeJ5Q0ZkgcAxY3x259DQtm4LvI1/we0gTMAgoV6Xq4saFW5t63Kt/XJmdu9OorIFA/Wt2/xsTvaGK11U89mH950wR6YgN8wD09S6Z1C5m5H0Z0C96fdafztf/IOE+MEic5aIN4mTTYvDMLY3s1sbi5iKkMr7S6W12mfb3Wi9VTtNLVxpYPbnicFk8/5cauJsd+PC6/QMJ7yaso9qYJPw7RMuJx+VdP+9TF2wzA6gDIsHNKVyVYFenhjC1tffHBjqlAQRU2UqyQ6G6oISiFaRzL/XjggNF0kM7F+rFqmkLaRQPfuxGgPj/A08e+9DnQ5/yACpeLw10zMDg3ox7x0nHU7x4Mj4JQ46YwJygGUqFj77a0WaSxVnwtLtc/BW32vh7Nkhvlzhdja15+MybBMfEnQxTLXBs2rTvcZ+h+SPWbL7dvIhT4J6zWyJyxy1yb6YPHzw8Ai1vNWbuO6aUxz8S81DhVd2hfA==\"\n",
    "\n",
    "print(\"‚úÖ Temporary credentials set as environment variables for this session.\")\n",
    "\n",
    "# --- Import the official utility functions ---\n",
    "try:\n",
    "    from src.utils.gdsc_utils import aws_signed_request, chat_with_persona\n",
    "    print(\"‚úÖ Successfully imported GDSC utility functions.\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Failed to import GDSC utility functions: {e}\")\n",
    "    print(\"   Make sure the notebook is in the project root directory.\")\n",
    "    # Stop execution if import fails\n",
    "    raise\n",
    "\n",
    "# --- Test 1: Health Check ---\n",
    "print(\"\\n--- ü©∫ Testing Connection to GDSC API /health endpoint ---\")\n",
    "health_check_success = aws_signed_request(\"health\", \"GET\", verbose=True)\n",
    "\n",
    "if not health_check_success:\n",
    "    print(\"\\nüö´ Health check FAILED. Cannot proceed to chat test.\")\n",
    "else:\n",
    "    print(\"\\n--- üí¨ Testing a live chat with persona_001 ---\")\n",
    "    # This is a more comprehensive test.\n",
    "    # We expect a tuple (response_text, conversation_id)\n",
    "    chat_response = chat_with_persona(\n",
    "        persona_id=\"persona_001\",\n",
    "        message=\"Hello\",\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    if chat_response:\n",
    "        print(\"\\nüéâ SUCCESS! You have successfully authenticated and chatted with a persona.\")\n",
    "        print(f\"   Response from persona_001: '{chat_response[0]}'\")\n",
    "        print(f\"   Conversation ID: {chat_response[1]}\")\n",
    "    else:\n",
    "        print(\"\\nüö´ Chat test FAILED. The health check passed, but the chat did not.\")\n",
    "        print(\"   This could be an issue with the API payload or temporary permissions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea6cb36-8430-47c0-8054-ced12ee03751",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
