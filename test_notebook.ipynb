{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2927b3a-466c-417c-867f-a0f299d08dc4",
   "metadata": {},
   "source": [
    "### Test Mistral API connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1077983-abe5-488e-be42-279f27d99913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Setting up environment ---\n",
      "‚úÖ Found and loaded environment file from: .env\n",
      "‚úÖ API key found, we're ready to roll.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from mistralai import Mistral # CORRECTED: Import Mistral, not MistralClient\n",
    "\n",
    "print(\"--- 1. Setting up environment ---\")\n",
    "\n",
    "# Load your API key from .env file\n",
    "# This assumes your .env file is in the parent directory of the notebook's location\n",
    "env_path = \".env\"\n",
    "if os.path.exists(env_path):\n",
    "    load_dotenv(dotenv_path=env_path)\n",
    "    print(f\"‚úÖ Found and loaded environment file from: {env_path}\")\n",
    "else:\n",
    "    load_dotenv()\n",
    "    print(\"Trying to load from default location...\")\n",
    "\n",
    "# Check if the API key is now available\n",
    "if not os.getenv(\"MISTRAL_API_KEY\"):\n",
    "    print(\"‚ùå No MISTRAL_API_KEY found in environment!\")\n",
    "else:\n",
    "    print(\"‚úÖ API key found, we're ready to roll.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80fa0cc0-5c00-4dd2-885f-9a50478be352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mistral helper function is defined.\n"
     ]
    }
   ],
   "source": [
    "def call_mistral_directly(prompt: str, model: str = \"mistral-small-latest\") -> dict | None:\n",
    "    \"\"\"\n",
    "    Calls the Mistral API directly using the official, correct method.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- 2. Preparing to call Mistral with model: {model} ---\")\n",
    "    \n",
    "    api_key = os.environ.get(\"MISTRAL_API_KEY\")\n",
    "    if not api_key:\n",
    "        print(\"‚ùå Cannot call API, MISTRAL_API_KEY is not set.\")\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        # Initialize the new Mistral client\n",
    "        client = Mistral(api_key=api_key)\n",
    "        \n",
    "        # Prepare the messages payload\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        \n",
    "        # Start timer and make the API call\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # CORRECTED: The official method is client.chat.complete()\n",
    "        response = client.chat.complete(\n",
    "            model=model,\n",
    "            messages=messages\n",
    "        )\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Extract useful info from the response\n",
    "        result = {\n",
    "            \"content\": response.choices[0].message.content,\n",
    "            \"model\": response.model,\n",
    "            \"duration\": end_time - start_time,\n",
    "            \"input_tokens\": response.usage.prompt_tokens,\n",
    "            \"output_tokens\": response.usage.completion_tokens,\n",
    "            \"total_tokens\": response.usage.total_tokens\n",
    "        }\n",
    "        \n",
    "        print(\"‚úÖ API call successful.\")\n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå API call failed: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ Mistral helper function is defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea64a011-6624-448d-9eaf-9d0e6994e9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3. Executing test with prompt: 'What is a 'green job'? Keep it short and practical.' ---\n",
      "\n",
      "--- 2. Preparing to call Mistral with model: mistral-small-latest ---\n",
      "‚úÖ API call successful.\n",
      "\n",
      "==============================\n",
      "üìä TEST CALL RESULTS üìä\n",
      "==============================\n",
      "  Model: mistral-small-latest\n",
      "  Time: 1.15 seconds\n",
      "  Input tokens: 17\n",
      "  Output tokens: 90\n",
      "  Total tokens: 107\n",
      "  Estimated cost: $0.000032\n",
      "\n",
      "------------------------------\n",
      "üí¨ RESPONSE üí¨\n",
      "------------------------------\n",
      "A **green job** is a role that helps reduce environmental harm or supports sustainability. Examples include:\n",
      "\n",
      "- **Renewable energy** (solar/wind technicians)\n",
      "- **Energy efficiency** (insulation installers, HVAC engineers)\n",
      "- **Waste management** (recycling coordinators)\n",
      "- **Conservation** (forestry, wildlife protection)\n",
      "\n",
      "Key traits: **Eco-friendly, sustainable, and often growing in demand.**\n",
      "\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# A simple test prompt to ensure everything works\n",
    "test_prompt = \"What is a 'green job'? Keep it short and practical.\"\n",
    "\n",
    "print(f\"\\n--- 3. Executing test with prompt: '{test_prompt}' ---\")\n",
    "result = call_mistral_directly(test_prompt)\n",
    "\n",
    "if result:\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"üìä TEST CALL RESULTS üìä\")\n",
    "    print(\"=\"*30)\n",
    "    print(f\"  Model: {result['model']}\")\n",
    "    print(f\"  Time: {result['duration']:.2f} seconds\")\n",
    "    print(f\"  Input tokens: {result['input_tokens']}\")\n",
    "    print(f\"  Output tokens: {result['output_tokens']}\")\n",
    "    print(f\"  Total tokens: {result['total_tokens']}\")\n",
    "    \n",
    "    # Using pricing for mistral-small-latest as of late 2024\n",
    "    # Input: ~$0.3/M tokens, Output: ~$0.3/M tokens\n",
    "    # We use the higher value for a conservative cost estimate\n",
    "    cost_per_million_tokens = 0.30 \n",
    "    estimated_cost = (result['total_tokens'] / 1_000_000) * cost_per_million_tokens\n",
    "    print(f\"  Estimated cost: ${estimated_cost:.6f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*30)\n",
    "    print(\"üí¨ RESPONSE üí¨\")\n",
    "    print(\"-\"*30)\n",
    "    print(result['content'])\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "else:\n",
    "    print(\"\\n--- Test failed. Please check the error message above. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ec9b33-b697-43b7-9d7d-fcce57117d58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
